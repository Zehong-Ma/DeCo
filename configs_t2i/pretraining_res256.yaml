# lightning.pytorch==2.4.0
seed_everything: true
tags:
  exp: &exp pretraining_pix256
torch_hub_dir: ~/.cache/torch/hub
ckpt_path: /data/code/PixNerd/universal_pix_t2i_workdirs/exp_pretraining_pix256/epoch=0-step=160000.ckpt
huggingface_cache_dir: null
trainer:
  default_root_dir: ./universal_pix_t2i_workdirs
  accelerator: auto
  strategy: ddp
  devices: auto
  num_nodes: 1
  accumulate_grad_batches: 3
  precision: bf16-mixed
  logger:
      class_path: lightning.pytorch.loggers.TensorBoardLogger
      init_args:
        save_dir: ./universal_pix_flow_t2i
        name: *exp
  num_sanity_val_steps: 2
  max_steps: 200000
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
  val_check_interval: 20000
  check_val_every_n_epoch: null
  log_every_n_steps: 50
  deterministic: null
  inference_mode: true
  use_distributed_sampler: false
  callbacks:
    - class_path: src.callbacks.model_checkpoint.CheckpointHook
      init_args:
        every_n_train_steps: 10000
        save_top_k: -1
        save_last: true
    - class_path: src.callbacks.save_images.SaveImagesHook
      init_args:
         save_dir: val
  plugins:
    - src.plugins.bd_env.BDEnvironment
model:
  vae:
    class_path: src.models.autoencoder.pixel.PixelAE
  denoiser:
    class_path: src.models.transformer.dit_t2i_DeCo.PixNerDiT
    init_args:
      in_channels: 3
      patch_size: 16
      num_groups: 24
      hidden_size: &hidden_dim 1536
      txt_embed_dim: &txt_embed_dim 2048
      txt_max_length: 128
      num_text_blocks: 4
      decoder_hidden_size: 32
      num_encoder_blocks: 16
      num_decoder_blocks: 3
  conditioner:
    class_path: src.models.conditioner.qwen3_text_encoder.Qwen3TextEncoder
    init_args:
      weight_path: /data/pretrained_weights/Qwen/Qwen3-1.7B
      embed_dim: *txt_embed_dim
      max_length: 128
  diffusion_trainer:
    class_path: src.diffusion.flow_matching.training_repa_DeCo.REPATrainer
    init_args:
      lognorm_t: true
      feat_loss_weight: 0.5
      timeshift: 2.0
      encoder:
        class_path: src.models.encoder.DINOv2
        init_args:
          weight_path: /root/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth
      align_layer: 6
      proj_denoiser_dim: *hidden_dim
      proj_hidden_dim: *hidden_dim
      proj_encoder_dim: 768
      scheduler: &scheduler src.diffusion.flow_matching.scheduling.LinearScheduler
  diffusion_sampler:
    class_path: src.diffusion.flow_matching.sampling.EulerSampler
    init_args:
      num_steps: 100
      guidance: 4.0
      scheduler: *scheduler
      w_scheduler: src.diffusion.flow_matching.scheduling.LinearScheduler
      guidance_fn: src.diffusion.base.guidance.simple_guidance_fn
      step_fn: src.diffusion.flow_matching.sampling.ode_step_fn
  ema_tracker:
    class_path: src.callbacks.simple_ema.SimpleEMA
    init_args:
      decay: 0.9999
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 2e-4
      betas:
        - 0.9
        - 0.95
      weight_decay: 0.00
data:
  train_dataset:
    class_path: src.data.dataset.blip3o_dataset.WebDatasetPackedDataset
    init_args:
      urls: [/data/datasets/BLIP-3o/BLIP3o-Pretrain-Long-Caption, /data/datasets/BLIP-3o/BLIP3o-Pretrain-Short-Caption, /data/datasets/BLIP-3o/BLIP3o-Pretrain-JourneyDB] # [/data/datasets/BLIP-3o/BLIP3o-Pretrain-JourneyDB,]
      resolution: 256
      random_crop: false
      shuffle_buffer: 20000
      sample_shuffle: true
      repeat: true
  eval_dataset:
    class_path: src.data.dataset.geneval.GenEvalDataset
    init_args:
      meta_json_path: ./evaluations/geneval/evaluation_metadata.jsonl
      num_samples_per_instance: 4
      latent_shape:
        - 3
        - 256
        - 256
  pred_dataset:
    class_path: src.data.dataset.geneval.GenEvalDataset
    init_args:
      # meta_json_path: ./evaluations/geneval/evaluation_metadata_rephrased.jsonl
      meta_json_path: ./evaluations/geneval/evaluation_metadata.jsonl
      num_samples_per_instance: 4
      latent_shape:
        - 3
        - 256
        - 256
  train_batch_size: 64 # 96
  train_num_workers: 8
  pred_batch_size: 8
  pred_num_workers: 1